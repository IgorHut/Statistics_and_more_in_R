---
title: Correlation tests, correlation matrix, and corresponding visualization methods
  in R
author: "Igor Hut"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    toc: yes
    toc_depth: 4
  html_notebook: default
  pdf_document:
    toc: yes
    toc_depth: '3'
---

**The following content is mostly compiled (with some original additions on my side) from the material that can be found at <http://www.sthda.com/>, as well as in the vignette for the `corrplot` R package - [An Introduction to corrplot Package](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html). The sole purpose of this text is to put all the info into one document in an easy to search format. Since I'm a huge fan of Hadley Wickham's work I'll insist on solutions based in ["tidyverse"](https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/) whenewer possible...**


### Install and load required R packages

We'll use the `ggpubr` R package for an easy ggplot2-based data visualization, `corrplot` package to plot correlograms, `Hmisc` to calculate correlation matrices containing both cor. coefs. and p-values,`corrplot` for plotting correlograms, and of course `tidyverse` for all the data wrangling, plotting and alike:
```{r, message=FALSE, warning=FALSE}
require(ggpubr)
require(tidyverse)
require(Hmisc)
require(corrplot)
```

## Methods for correlation analyses

There are different methods to perform correlation analysis:

- **Pearson correlation (r)**, which measures a linear dependence between two variables (x and y). It's also known as a parametric correlation test because it depends to the distribution of the data. It can be used only when x and y are from normal distribution. The plot of *y = f(x)* is named the *linear regression curve*.

- **Kendall $\tau$** and **Spearman $\rho$**, which are rank-based correlation coefficients (non-parametric)

- **The most commonly used method is the Pearson correlation method**

## Compute correlation in R

### R functions

Correlation coefficients can be computed in R by using the functions `cor()` and `cor.test()`:

> 
- `cor()` computes the correlation coefficient
- `cor.test()` test for association/correlation between paired samples. It returns both the correlation coefficient and the significance level(or p-value) of the correlation.

*The simplified formats are:*
```{r, eval=FALSE, message=FALSE}
cor(x, y, method = c("pearson", "kendall", "spearman"))
cor.test(x, y, method=c("pearson", "kendall", "spearman"))
```

where:

> 
- x, y: numeric vectors with the same length
- method: correlation method


**If the data contain missing values, the following R code can be used to handle missing values by case-wise deletion:**
```{r, eval=FALSE}
cor(x, y,  method = "pearson", use = "complete.obs")
```

## Preliminary considerations 

We'll use the well known built-in `mtcars` R dataset.
```{r}
head(mtcars)
```

> We'd like to compute the correlation between `mpg` and `wt` variables.

**First let's visualise our data by the means of a scatter plot. We'll be using `ggpubr` R package**

```{r}
library(ggpubr)

my_data <- mtcars
my_data$cyl <- factor(my_data$cyl)
str(my_data)

ggscatter(my_data, x = "wt", y = "mpg",
          add = "reg.line", conf.int = TRUE,
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Weight (1000 lbs)", ylab = "Miles/ (US) gallon")
```

### Preleminary test to check the test assumptions

1. Is the relation between variables linear? Yes, from the plot above, the relationship can be, closely enough, modeled as linear. In the situation where the scatter plots show curved patterns, we are dealing with nonlinear association between the two variables.

2. Are the data from each of the 2 variables (x, y) following a normal distribution?
    - Use *Shapiro-Wilk* normality test $\rightarrow$ R function: `shapiro.test()` 
    - and look at the normality plot $\rightarrow$ R function: `ggpubr::ggqqplot()`

- *Shapiro-Wilk* test can be performed as follow:
    - Null hypothesis: the data are normally distributed
    - Alternative hypothesis: the data are not normally distributed
    
```{r}
# Shapiro-Wilk normality test for mpg
shapiro.test(my_data$mpg) # => p = 0.1229

# Shapiro-Wilk normality test for wt
shapiro.test(my_data$wt) # => p = 0.09
```
*As can be seen from the output, the two p-values are greater than the predetermined significance level of 0.05 implying that the distribution of the data are not significantly different from normal distribution. In other words, we can assume the normality.*

- One more option for checking the normality of the data distribution is visual inspection of the Q-Q plots (quantile-quantile plots). Q-Q plot draws the correlation between a given sample and the theoretical normal distribution.

Again, we'll use the `ggpubr` R package to obtain "pretty", i.e. publishing-ready, Q-Q plots.

```{r}
library("ggpubr")
# Check for the normality of "mpg""
ggqqplot(my_data$mpg, ylab = "MPG")

# Check for the normality of "wt""
ggqqplot(my_data$wt, ylab = "WT")
```

*From the Q-Q normality plots, we can assume that both samples may come from populations that, closely enough, follow normal distributions.*

**It is important to note that if the data does not follow the normal distribution, at least closely enough, it's recommended to use the non-parametric correlation, including Spearman and Kendall rank-based correlation tests.**

## Pearson correlation test

**Example:**

```{r}
res <- cor.test(my_data$wt, my_data$mpg, method = "pearson")
res
```

So what's happening here? First of all let's clarify the meaning of this printout:

- `t` is the *t-test* statistic value `(t = -9.559)`,
- `df` is the degrees of freedom `(df= 30)`,
- `p-value` is the significance level of the *t-test* `(p-value =` $1.29410^{-10}$`)`.
- `conf.int` is the *confidence interval* of the correlation coefficient at 95% `(conf.int = [-0.9338, -0.7441])`;
- `sample estimates` is the *correlation coefficient* `(Cor.coeff = -0.87)`.

**Interpretation of the results:**
As can be see from the results above the *p-value* of the test is $1.29410^{-10}$, which is less than the significance level $\alpha = 0.05$. We can conclude that `wt` and `mpg` are significantly correlated with a correlation coefficient of -0.87 and *p-value* of $1.29410^{-10}$.

**Access to the values returned by `cor.test()` function**

The function `cor.test()` returns a list containing the following components:

```{r}
str(res)
```
Of these we are most interested with:

- `p.value`: the p-value of the test
- `estimate`: the correlation coefficient

```{r}
# Extract the p.value
res$p.value

# Extract the correlation coefficient
res$estimate
```

## Kendall rank correlation test

**The Kendall rank correlation coefficient** or **Kendall's $\tau$ statistic** is used to estimate a rank-based measure of association. This test may be used if the data do not necessarily come from a bivariate normal distribution.

```{r}
res2 <- cor.test(my_data$mpg, my_data$wt, method = "kendall")

res2
```

Here `tau` is the Kendall correlation coefficient, so The correlation coefficient between `mpg` and `wy` is -0.7278 and the p-value is $6.70610^{-9}$.

## Spearman rank correlation coefficient

**Spearman's $\rho$ statistic** is also used to estimate a rank-based measure of association. This test may be used if the data do not come from a bivariate normal distribution.

```{r}
res3 <- cor.test(my_data$wt, my_data$mpg, method = "spearman")

res3
```
Here, `rho` is the Spearman's correlation coefficient, so the correlation coefficient between `mpg` and `wt` is -0.8864 and the p-value is $1.48810^{-11}$.

## How to interpret correlation coefficient

**Value of the correlation coefficient can vary between -1 and 1:**

- -1 indicates a strong negative correlation : this means that every time x increases, y decreases 
- 0 means that there is no association between the two variables (x and y) 
- 1 indicates a strong positive correlation : this means that y increases with x 


## What is a correlation matrix?

Previously, we described how to perform correlation test between two variables. In the following sections we'll see how a **correlation matrix** can be computed and visualized. The **correlation matrix** is used to investigate the dependence between multiple variables at the same time. The result is a table containing the correlation coefficients between each variable and the others.

## Compute correlation matrix in R

We have already mentioned the `cor()` function, at the intoductory part of this document dealing with the correlation test for a bivariate case. It be used to compute a correlation matrix. A simplified format of the function is :

```{r, eval=FALSE, message=FALSE}
cor(x, method = c("pearson", "kendall", "spearman")) 
```
Here:

- `x` is numeric matrix or a data frame.
- `method`: indicates the correlation coefficient to be computed. The default is "pearson"" correlation coefficient which measures the linear dependence between two variables. As already explained "kendall" and "spearman" correlation methods are non-parametric rank-based correlation tests.

If your data contain missing values, the following R code can be used to handle missing values by case-wise deletion:

```{r, eval=FALSE, message=FALSE}
cor(x, method = "pearson", use = "complete.obs")
```

### Plain correlation matrix
**Example:**
```{r}
library(dplyr)

my_data <- select(mtcars, mpg, disp, hp, drat, wt, qsec)
head(my_data)

#Let's compute the correlation matrix
cor_1 <- round(cor(my_data), 2)
cor_1

```

Unfortunately, the function `cor()` returns only the correlation coefficients between variables. In the next section, we will use `Hmisc` R package to calculate the correlation *p-values*.

### Correlation matrix with significance levels (p-value)

The function `rcorr()` (in `Hmisc` package) can be used to compute the significance levels for pearson and spearman correlations. It returns both the *correlation coefficients* and the *p-value* of the correlation for all possible pairs of columns in the data table.

*Simplified format:*
```{r, eval=FALSE, message=FALSE}
rcorr(x, type = c("pearson","spearman"))
```
*x* should be a matrix. The correlation type can be either *pearson* or *spearman*.

**Example:**
```{r}
library("Hmisc")

cor_2 <- rcorr(as.matrix(my_data))
cor_2
```
The output of the function `rcorr()` is a list containing the following elements : 

- **r** : the correlation matrix
- **n** : the matrix of the number of observations used in analyzing each pair of variables 
- **P** : the p-values corresponding to the significance levels of correlations.

Extracting the p-values or the correlation coefficients from the output:
```{r}
str(cor_2)

# As you can see "cor_2" is a list so extracting these values is quite simple...

# p-values
cor_2$P

# Correlation matrix
cor_2$r
```


## Custom function for convinient formatting of the correlation matrix

This section provides a simple function for formatting a correlation matrix into a table with 4 columns containing :

- Column 1 : row names (variable 1 for the correlation test)
- Column 2 : column names (variable 2 for the correlation test)
- Column 3 : the correlation coefficients
- Column 4 : the p-values of the correlations

```{r}

flat_cor_mat <- function(cor_r, cor_p){
  #This function provides a simple formatting of a correlation matrix
  #into a table with 4 columns containing :
    # Column 1 : row names (variable 1 for the correlation test)
    # Column 2 : column names (variable 2 for the correlation test)
    # Column 3 : the correlation coefficients
    # Column 4 : the p-values of the correlations
  library(tidyr)
  library(tibble)
  cor_r <- rownames_to_column(as.data.frame(cor_r), var = "row")
  cor_r <- gather(cor_r, column, cor, -1)
  cor_p <- rownames_to_column(as.data.frame(cor_p), var = "row")
  cor_p <- gather(cor_p, column, p, -1)
  cor_p_matrix <- left_join(cor_r, cor_p, by = c("row", "column"))
  cor_p_matrix
}

cor_3 <- rcorr(as.matrix(mtcars[, 1:7]))

my_cor_matrix <- flat_cor_mat(cor_3$r, cor_3$P)
head(my_cor_matrix)
```

## Visualization of a correlation matrix

There are several different ways for visualizing a correlation matrix in R software:

- `symnum()` function
- `corrplot()` function to plot a correlogram
- scatter plots
- heatmap

We'll run trough all of these, and then go a bit more into deatil with correlograms.

### Use `symnum()` function: Symbolic number coding

The R function `symnum()` is used to symbolically encode a given numeric or logical vector or array. It is particularly useful for visualization of structured matrices, e.g., correlation, sparse, or logical ones. In the case of a correlatino matrix it replaces correlation coefficients by symbols according to the level of the correlation. 

*Simplified format:*

```{r, eval=FALSE, message=FALSE, warning=FALSE}
symnum(x, cutpoints = c(0.3, 0.6, 0.8, 0.9, 0.95),
       symbols = c(" ", ".", ",", "+", "*", "B"),
       abbr.colnames = TRUE)
```
Here:

- **x:** the correlation matrix to visualize
- **cutpoints:** correlation coefficient cutpoints. The correlation coefficients between 0 and 0.3 are replaced by a space (" "); correlation coefficients between 0.3 and 0.6 are replaced by"."; etc .
- **symbols:** the symbols to use.
- **abbr.colnames:** logical value. If TRUE, colnames are abbreviated.

**Example:**
```{r}

cor_4 <- cor(mtcars[1:6])
symnum(cor_4, abbr.colnames = FALSE)
```

*As indicated in the legend, the correlation coefficients between 0 and 0.3 are replaced by a space (" "); correlation coefficients between 0.3 and 0.6 are replace by"."; etc .*

### Use the `corrplot()` function: Draw a correlogram

The function `corrplot()`, in the package of the same name, creates a graphical display of a correlation matrix, highlighting the most correlated variables in a data table.

In this plot, correlation coefficients are colored according to the value. Correlation matrix can be also reordered according to the degree of association between variables.

*The simplified format of the function is:*
```{r, eval=FALSE, message=FALSE, warning=FALSE}
corrplot(corr, method="circle")
```
Here:

- **corr:** the correlation matrix to be visualized
- **method:** The visualization method to be used, there are seven different options: "circle", "square", "ellipse", "number", "shade", "color", "pie".

**Example:**

```{r}
M<-cor(mtcars)
head(round(M,2))

#Visualize the correlation matrix

# method = "circle""
corrplot(M, method = "circle")

# method = "ellipse""
corrplot(M, method = "ellipse")

# method = "pie"
corrplot(M, method = "pie")

# method = "color"
corrplot(M, method = "color")
```

*Display the **correlation coefficient**:*
```{r}
corrplot(M, method = "number")
```

#### Correlogram layouts:

There are three general types of a correlogram layout :

- **"full"** (default) : display full correlation matrix
- **"upper"**: display upper triangular of the correlation matrix
- **"lower"**: display lower triangular of the correlation matrix

**Examples:**
```{r}
# upper triangular
corrplot(M, type = "upper")

#lower triangular
corrplot(M, type = "lower")
```

#### Reordering the correlation matrix

The correlation matrix can be reordered according to the correlation coefficient. This is important to identify the hidden structure and pattern in the matrix. Use `order = "hclust"` argument for hierarchical clustering of correlation coefficients.

**Example:**
```{r}
# correlogram with hclust reordering
corrplot(M, order = "hclust")

# or exploit the symetry of the correlation matrix 
# correlogram with hclust reordering
corrplot(M, type = "upper", order = "hclust")
```

#### Changing the color and direction of text labels in the correlogram

**Examples:**
```{r}
# Change background color to lightgreen and color of the circles to darkorange and steel blue
corrplot(M, type = "upper", order = "hclust", col = c("darkorange", "steelblue"),
         bg = "lightgreen")

# use "colorRampPallete" to obtain contionus color scales
col <- colorRampPalette(c("darkorange", "white", "steelblue"))(20)
corrplot(M, type = "upper", order = "hclust", col = col)

# Or use "RColorBrewer" package
library(RColorBrewer)
corrplot(M, type = "upper", order = "hclust",
         col = brewer.pal(n = 9, name = "PuOr"), bg = "darkgreen")
```

Use the **`tl.col`** argument for defining the text label color and **`tl.srt`** for text label string rotation.

**Example:**
```{r}
corrplot(M, type = "upper", order = "hclust", tl.col = "darkblue", tl.srt = 45)
```

#### Combining correlogram with the significance test

```{r}
# Mark the insignificant coefficients according to the specified p-value significance level
cor_5 <- rcorr(as.matrix(mtcars))
M <- cor_5$r
p_mat <- cor_5$P
corrplot(M, type = "upper", order = "hclust", 
         p.mat = p_mat, sig.level = 0.01)

# Leave blank on no significant coefficient
corrplot(M, type = "upper", order = "hclust", 
         p.mat = p_mat, sig.level = 0.05, insig = "blank")
```

#### Fine tuning customization of the correlogram

```{r}
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method = "color", col = col(200),  
         type = "upper", order = "hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "darkblue", tl.srt = 45, #Text label color and rotation
         # Combine with significance level
         p.mat = p_mat, sig.level = 0.01,  
         # hide correlation coefficient on the principal diagonal
         diag = FALSE 
         )
```

I'd say this is more than enough for introductory exploration of correlograms. More information can be found in the, already mentioned, vignette for the `corrplot` R package - [An Introduction to corrplot Package](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)

### Use `chart.Correlation()`: Draw scatter plots

The function `chart.Correlation()` from the package "`PerformanceAnalytics`", can be used to display a chart of a correlation matrix. This is a very convinient way of exploring multivariate correlations.

```{r, warning=FALSE}
library("PerformanceAnalytics")
my_data <- mtcars[, c(1,3,4,5,6,7)]
chart.Correlation(my_data, histogram = TRUE, pch = 19)
```

In the above plot:

- The distribution of each variable is shown on the diagonal.
- On the bottom of the diagonal : the bivariate scatter plots with a fitted line are displayed
- On the top of the diagonal : the value of the correlation plus the significance level as stars
- Each significance level is associated to a symbol : p-values(0, 0.001, 0.01, 0.05, 0.1, 1) <=> symbols("***", "**", "*", ".", " ")

### Use `heatmap()`

I don't really consider this method of correlation matrix visualization to be of practical value, but nevertheless here is a small example:

```{r}
# Get some colors
col <- colorRampPalette(c("darkblue", "white", "darkorange"))(20)
M <- cor(mtcars[1:7])
heatmap(x = M, col = col, symm = TRUE)
```